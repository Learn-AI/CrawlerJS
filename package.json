{
  "name": "crawlerjs",
  "version": "1.0.0",
  "description": "Opensource web data extraction framework for Node.js",
  "main": "./lib/crawler.js",
  "directories": {
    "example": "examples",
    "test": "test"
  },
  "scripts": {
    "test": "make test"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/CrawlerJS/CrawlerJS.git"
  },
  "keywords": [
    "crawler",
    "scrapy",
    "hacker",
    "crawlers",
    "robots",
    "robot",
    "dom",
    "extraction",
    "nsa",
    "bigdata"
  ],
  "author": "Rodrigo Matheus <rodrigorizando@gmail.com>",
  "license": "ISC",
  "bugs": {
    "url": "https://github.com/CrawlerJS/CrawlerJS/issues"
  },
  "homepage": "https://github.com/CrawlerJS/CrawlerJS",
  "devDependencies": {
    "chai": "2.1.2",
    "coveralls": "2.11.2",
    "grunt": "0.4.5",
    "grunt-cli": "0.1.13",
    "grunt-run": "0.3.0",
    "istanbul": "0.3.8",
    "jshint": "2.5.6",
    "mocha": "2.2.1",
    "nock": "1.2.0"
  },
  "dependencies": {
    "bluebird": "2.3.6",
    "eventary": "2.0.1",
    "grunt-jsdoc-to-markdown": "1.1.1",
    "handlebars": "3.0.0",
    "joi": "6.0.8",
    "mustache": "1.1.0",
    "r...e": "0.2.0",
    "request": "2.45.0",
    "xmldom": "0.1.19",
    "xpath": "0.0.9"
  }
}
